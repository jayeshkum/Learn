{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Science - Python Script Repository.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrcMa1kp7nhDLyqvBJrmkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayeshkum/Learn-Data-Science/blob/master/Data_Science_Python_Script_Repository.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0rVNxtudofz"
      },
      "source": [
        "# **Data Science Repository of Python codes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrpvm5J1dMb2"
      },
      "source": [
        "This document intends to create a repository of Python codes, useful for any Data Scientist.\n",
        "\n",
        "At times, we know what to do, but may not remember how to. Ultimately resorting to internet search for required code blocks to do the regular exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OU3qV36d_KC"
      },
      "source": [
        "Importing required libraries:\n",
        "Default: Pandas, NumPy, OS, Matplotlib, Seaborn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7JisZPYeOyx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "# To get the output of matplotlib in the document itself, rather than seperate window\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lbPY2k6fKcl"
      },
      "source": [
        "Basic commands for using OS library:\n",
        "os.chdir(\"D:\\Pandas\") will change directory to D:\\Pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5x16LnXdydW"
      },
      "source": [
        "**Reading Data and basic information, description of data**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPnj4Z0zhn6U"
      },
      "source": [
        "### Reading CSV File ###\n",
        "To read a .csv file in the Data Frame, named as 'data'. This command will convert \"blank\" cells in CSV file to \"nan\" (read as Not a Number). It will also create an index column in dataframe (1st column) to represent row numbers:\n",
        "\n",
        "*data = pd.read_csv(\"path to file\")*\n",
        "\n",
        "\n",
        "Remove the extra column id by passing index_col=0:\n",
        "\n",
        "*data = pd.read_csv(\"path to file\", index_col=0)*\n",
        "\n",
        "There may be cases, when the CSV file contains a value to denote junk/blank data, such as \"??\", \"###\" etc. In that case, ask pandas to read these values as 'na_values':\n",
        "\n",
        "*data = pd.read_csv(\"path to file\", index_col=0, na_values=[\"??\", \"###\"])*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehq1AGd3dwTb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-feq3d9hsLo"
      },
      "source": [
        "### Reading a TXT file ###\n",
        "To read a text file (.txt) in the Data Frame, named as 'data'. This command will convert \"blank\" cells in CSV file to \"nan\" (read as Not a Number). It will also create an index column in dataframe (1st column) to represent row numbers:\n",
        "\n",
        "*data = pd.read_table(\"path to file\")*\n",
        "\n",
        "This will read all data in one columns, unless provided with a seperator/delimiter, as:\n",
        "\n",
        "*data = pd.read_table(\"path to file\", sep = \"\\t\")*\n",
        "*data = pd.read_table(\"path to file\", delimiter = \"\\t\")*\n",
        "\n",
        "Assuming the text file has data columns, seperated by Tab (denoted as \\t), in case of other delimiter in the above code, replace \\t with actual delimiter (for example, in case of space delimited, use delimiter = \" \".\n",
        "\n",
        "One can also use read_csv to read text file, by replacing sep=\",\". As CSV file is nothing but a text file with \",\" as a seperater."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k67r-6ZGklio"
      },
      "source": [
        "### Reading Excel file ###\n",
        "At times data may reside in an excel file, with multiple sheets. For reading data from one particular sheet of the excel file, use read_excel:\n",
        "\n",
        "*data = pd.read_excel(\"path to file\", sheet_name=\"data sheet\")*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp-Q3B5TjBi6"
      },
      "source": [
        "### Copy Data Frame ###\n",
        "There are two kinds of Copy options:\n",
        "\n",
        "1. Shallow Copy: *data_copy = data.copy(deep=False)* \n",
        "This will create a copy of the 'data' as 'data_copy', by creating a new variable that referes to same object. Any changes made in 'data_copy' will change 'data' as well.\n",
        "\n",
        "2. Deep copy: *deep_data_copy = data.copy(deep=True)*\n",
        "In case of a deep copy, a copy of the object is copied in another object with no reference to original object. Any changes made in the deep copy will have no effect on the original copy. (Recommendation: Use deep copy or create a new dataframe, if data is small)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JVxNb-BkFo3"
      },
      "source": [
        "##Attributes of Data##\n",
        "Next step, after reading the data from data source is to understand basic structure of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMq5Ig61lDAp"
      },
      "source": [
        "# Row labels of dataframe 'data' can be obtained by:\n",
        "data.index\n",
        "\n",
        "# Similarly, column labels of 'data' can be obtained by:\n",
        "data.columns\n",
        "\n",
        "# Dataframe size (total number of attributed):\n",
        "data.size\n",
        "\n",
        "# Shape of data:\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qePlonJzlN7U"
      },
      "source": [
        "# Dimension and memory usage can be obtained by:\n",
        "data.ndim\n",
        "data.memory_usage()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L_t6TD8l9hj"
      },
      "source": [
        "Python slicing operators: [] and . are used for indexing. Providing quick and easy access to pandas dataframe\n",
        "\n",
        "For example:\n",
        "\n",
        "*data.head(10)* \n",
        "\n",
        "Is the function to return the top /head /first 10 rows of the dataframe. Change the number '10' to print more /less number of rows. Use *.tail* command to get bottom /tail /last rows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b21A5-m3m7nt"
      },
      "source": [
        "### Indexing and selecting data ###\n",
        "To access a scalar value, use 'at' (label based) or 'iat' (index based)method.\n",
        "\n",
        "*data.at[row_number,'Column_name')*\n",
        "\n",
        "*data.iat[4,6]*\n",
        "\n",
        "To access a group of rows /columns, use '.loc[ ]' or 'iloc[ ]' method.\n",
        "\n",
        "*data.loc[:,\"Column_name\"]*\n",
        "\n",
        "*data.iloc[:,5]*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTuqafzvoGxH"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gqiwhj3owg0"
      },
      "source": [
        "# Checking data types #\n",
        "data.dtypes\n",
        "\n",
        "# Getting unique counts of different datatypes in the dataframe\n",
        "data.get_dtype_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E4x-Oi1pEq0"
      },
      "source": [
        "# Selecting data, based on the data type:\n",
        "data.select_dtypes(exclude=[object])\n",
        "\n",
        "# Above code will select part of dataframe, excluding columns with data type of \"Object\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vPa3wa_oG3P"
      },
      "source": [
        "### Summary / Exporation of Data Frame ###\n",
        "Understanding the basic structure of data frame is critical for any analysis. Followed by cleaning/formatting data in readable/usable format.\n",
        "\n",
        "### Information about dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGxWUuDkppNu"
      },
      "source": [
        "# info() Provides column names, number of non-null observations, and data type; followed by memory usage.\n",
        "data.info()\n",
        "\n",
        "# Describe gives 5 point summary of numerical columns.\n",
        "data.describe()\n",
        "\n",
        "# Mean, Median\n",
        "data['Col_Name'].mean()\n",
        "data['Col_Name'].median()\n",
        "\n",
        "# Value_Counts, gives frequency count of variable\n",
        "data['Col_Name'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1FUyE5FqOKf"
      },
      "source": [
        "# Finding unqiue observations in a column:\n",
        "print(np.unqiue(data['Col_Name']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qqsf776oG6t"
      },
      "source": [
        "### Data conversion , reformating, reshape etc ###\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XP89lkiqvrS"
      },
      "source": [
        "# Converting data type of columns, using 'astype'\n",
        "data['Col_Name'] = data['Col_Name'].astype('object')\n",
        "data['Col_Name'] = data['Col_Name'].astype('int64')\n",
        "data['Col_Name'] = data['Col_Name'].astype('float')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQLd4KJ2q_oO"
      },
      "source": [
        "# Replacing values in columns using .replace / .where\n",
        "data['Col_Name'].replace('Old_Data','New_data',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1FrCFz1q_rh"
      },
      "source": [
        "# Detecting missing values, lists all columns and missing values:\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grE-x-Pzq_yG"
      },
      "source": [
        "# Filling NaN values with mean/median\n",
        "data['Col_Name'].fillna(data['Col_Name'].mean(), inplace = True)\n",
        "\n",
        "# Without inplace=True, original dataset would not change."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeU5nDyur4Uw"
      },
      "source": [
        "## EDA ##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Ua_o9Tr6bU"
      },
      "source": [
        "# Frequency table / cross tabulation\n",
        "\n",
        "pd.crosstab(index=data['Col_Name'], columns='count', dropna=True)\n",
        "\n",
        "# Useful for categorical variables."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBL8MwifstNG"
      },
      "source": [
        "# For two variable cross-tabulation\n",
        "pd.crosstab(index = data['Col_Name_1'], columns = data['Col_Name_2'], dropna = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sgmCuUvueuo"
      },
      "source": [
        "# Two way table, join probablity:\n",
        "pd.crosstab(index = data['Col_Name_1'], columns = data['Col_Name_2'], normalize = True, dropna= True)\n",
        "\n",
        "# For marginal probability, add \" margins = True \" in the options. \n",
        "# For conditional probability, use \" normalize = 'index' \" rather than True, to get row-wise conditional probability. \n",
        "# Using \"normalize = 'columns' \" would give column wise conditional probability.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxoXLQd4vqRY"
      },
      "source": [
        "### Plots, Correlation ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LWfnMCWvn15"
      },
      "source": [
        "# Correlation table:\n",
        "data.corr()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQPUSviswGCg"
      },
      "source": [
        "# Scatter plot\n",
        "\n",
        "plt.scatter(data['Col_1'], data['Col_2'], c = 'red')\n",
        "# Scatter plot of Col_1 vs Col_2, using 'red' color\n",
        "# Add title, xlable, ylable: \n",
        "plt.title(\"Title\")\n",
        "plt.xlable(\"X-Lable\")\n",
        "plt.ylable(\"Y-Lable\")\n",
        "plt.show() # To show the chart\n",
        "\n",
        "# Histogram, Frequency distribution (dividing data in 10 bins, using blue color)\n",
        "plt.hist(data['Col_Name'], bins=10, color = 'blue')\n",
        "\n",
        "# Bar plot\n",
        "plt.bar(data['Col_Name_1'], data['Col_Name_2'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXPZUVvTwxkp"
      },
      "source": [
        "# Distribution Plot\n",
        "sns.distplot(data['Col'], kde=False) # KDE line\n",
        "\n",
        "# Regression Plot/ Scatter\n",
        "sns.set(style = \"darkgrid\")\n",
        "sns.regplot(x = data['Col_Name_1'], y = data['Col_Name_2'], fit_reg = True, marker =\"*\")\n",
        "\n",
        "# By deafult, fit_reg is True, change it to false for removing the regression line from the plot. \n",
        "# Change marker to denote points differently.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PBvei59yqHR"
      },
      "source": [
        "# Add Hue in line plot\n",
        "\n",
        "sns.lmplot(x = 'Col_1', y = 'Col_2', data = dataframe_name, fit_reg = False, hue = 'Col_3', legend = True, palette = \"Set1\")\n",
        "\n",
        "# Bar / Count Plot\n",
        "\n",
        "sns.countplot(x = 'Col_Name_1', data = 'dataframe', hue = 'Col_Name_2')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRLNaXt5zZxY"
      },
      "source": [
        "# Box / Wiskers plot \n",
        "\n",
        "sns.boxplot(y = data['Col_Name'])\n",
        "\n",
        "sns.boxplot(x = data['Col_Name_1'], y = data['Col_Name_2'], hue = data['Col_Name_3'])\n",
        "\n",
        "# Pairwise plots\n",
        "\n",
        "sns.pairplot(data, kind = 'scatter', hue = 'Col_Name')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOawns-C0OBo"
      },
      "source": [
        "## Tips & Tricks ##\n",
        "\n",
        "1. While giving \"index\" as parameter, setting index=0 means row-wise, and index=1 means column wise.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUyTovJe1p4u"
      },
      "source": [
        "# To get the mode of 'Col' variable:\n",
        "data['Col'].value_counts().index[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qaRln2B15TG"
      },
      "source": [
        "# Imputing missing values by mean for dataframe using lambda function\n",
        "\n",
        "filled_data = data.apply(lambda x: x.fillna(x.mean()) if x.dtype == 'float' else x.fillna(x.value_counts().index[0]))\n",
        "\n",
        "# This command repalces na values with column mean for float type and mode for other (i.e. object type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSMSDWq32XUh"
      },
      "source": [
        "driver = webdriver.PhantomJS(executable_path=r'E:\\PATH\\phantomjs\\bin\\phantomjs')\n",
        "#Web scraping add PATH\n",
        "# pip install phantomjs\n",
        "# pip install webdriver-manager\n",
        "# pip install urllib3\n",
        "# pip install bs4\n",
        "# pip install requests\n",
        "# pip install selenium\n",
        "# pip install geckodriver"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}